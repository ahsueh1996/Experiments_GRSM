Wed Dec  6 22:20:08 UTC 2017
[95m===============================================
Starting experiment: /home/hibench-output/baseline_standalone
================================================[97m
my ip:
147.75.202.66
end
[95m===============================================
Restarting Spark Master @ 147.75.202.66:7077
================================================[97m
Wed Dec  6 22:20:10 UTC 2017
Wed Dec  6 22:21:27 UTC 2017
[95m===============================================
To check the webUI to see the spark master,
  run the following: ssh -L 8080:localhost:8080 root@147.75.202.66
  then do following: xdg-open 147.75.202.66:8080
================================================[97m
[95m===============================================
Preparing for LR example, input size 150000 features....
================================================[97m
Wed Dec  6 22:21:40 UTC 2017
patching args=
start LogisticRegressionDataPrepare bench
Export env: SPARKBENCH_PROPERTIES_FILES=/CMC/kmiecseb/HiBench/report/lr/prepare/conf/sparkbench/sparkbench.conf
LIBJARS: 
JAR: /CMC/kmiecseb/HiBench/sparkbench/assembly/target/sparkbench-assembly-6.1-SNAPSHOT-dist.jar
args: hdfs://localhost:9000/HiBench/LR/Input 10000 150000
!!!!-----README-----!!!
Submit Spark job: /CMC/kmiecseb/spark/bin/spark-submit  --properties-file /CMC/kmiecseb/HiBench/report/lr/prepare/conf/sparkbench/spark.conf --class com.intel.hibench.sparkbench.ml.LogisticRegressionDataGenerator --master spark://147.75.202.66:7077  /CMC/kmiecseb/HiBench/sparkbench/assembly/target/sparkbench-assembly-6.1-SNAPSHOT-dist.jar hdfs://localhost:9000/HiBench/LR/Input 10000 150000
Output Path: hdfs://localhost:9000/HiBench/LR/Input
Num of Examples: 10000
Num of Features: 150000
finish LogisticRegressionDataPrepare bench
Wed Dec  6 22:22:46 UTC 2017
[95m=======================
Current settings, abort if wrong.
==========================[39m
ARM_MACHINE=true
YARN_CORES=92
YARN_MEM=112640
USE_YARN_FOR_SPARK_ON_HADOOP=false
SPARK_EXECUTOR_CORES=15
SPARK_EXECUTOR_MEMORY=16g
SPARK_DRIVER_MEMORY=24g
SPARK_WORKER_CORES=90
SPARK_WORKER_MEMORY=122g
SPARK_WORKER_INSTANCES=1
SPARK_EXECUTOR_INSTANCES=6
SPARK_DAEMON_MEMORY=2g
SPARK_DEFAULT_PARALLELISM=30
SPARK_SQL_SHUFFLE_PARTITIONS=30

[95m===================================
Resetting relavent configs
======================================[97m
[95m===============================================
Starting Spark LR example, 150000 features, trial baseline, @ spark://147.75.202.66:7077...
================================================[97m
[91mCHECK to make sure sparkmasters match!!!!!![97m
Wed Dec  6 22:22:49 UTC 2017
# JMH version: 1.19
# VM version: JDK 1.8.0-release, VM 25.71-b00
# VM invoker: /CMC/kmiecseb/jdk8u-server-release-1708/jre/bin/java
# VM options: -Xmx24g
# Warmup: 1 iterations, single-shot each
# Measurement: 5 iterations, single-shot each
# Timeout: 10 min per iteration
# Threads: 1 thread
# Benchmark mode: Single shot invocation time
# Benchmark: grsm.Benchmarks.Binary_LR

# Run progress: 0.00% complete, ETA 00:00:00
# Fork: 1 of 1
# Warmup Iteration   1: 

(spark.network.timeout,600s)
(spark.master,spark://147.75.202.66:7077)
(spark.app.name,JMH prof: LogisticRegressionWithLBFGS)
(spark.jars,/home/hsuehku1/Experiments_GRSM/jmh-spark/treeAggregate/.target/tmp-benchmarks.jar)
141.158 s/op
Iteration   1: 106.383 s/op
Iteration   2: 105.441 s/op
Iteration   3: 104.622 s/op
Iteration   4: 105.945 s/op
Iteration   5: 105.649 s/op


Result "grsm.Benchmarks.Binary_LR":
  N = 5
  mean =    105.608 ?(99.9%) 2.522 s/op

  Histogram, s/op:
    [104.000, 104.250) = 0 
    [104.250, 104.500) = 0 
    [104.500, 104.750) = 1 
    [104.750, 105.000) = 0 
    [105.000, 105.250) = 0 
    [105.250, 105.500) = 1 
    [105.500, 105.750) = 1 
    [105.750, 106.000) = 1 
    [106.000, 106.250) = 0 
    [106.250, 106.500) = 1 
    [106.500, 106.750) = 0 

  Percentiles, s/op:
      p(0.0000) =    104.622 s/op
     p(50.0000) =    105.649 s/op
     p(90.0000) =    106.383 s/op
     p(95.0000) =    106.383 s/op
     p(99.0000) =    106.383 s/op
     p(99.9000) =    106.383 s/op
     p(99.9900) =    106.383 s/op
     p(99.9990) =    106.383 s/op
     p(99.9999) =    106.383 s/op
    p(100.0000) =    106.383 s/op


# JMH version: 1.19
# VM version: JDK 1.8.0-release, VM 25.71-b00
# VM invoker: /CMC/kmiecseb/jdk8u-server-release-1708/jre/bin/java
# VM options: -Xmx24g
# Warmup: <none>
# Measurement: 1 iterations, single-shot each
# Timeout: 10 min per iteration
# Threads: 1 thread
# Benchmark mode: Single shot invocation time
# Benchmark: grsm.Benchmarks.Binary_LRi_acc

# Run progress: 40.00% complete, ETA 00:16:53
# Fork: 1 of 1
Iteration   1: 

(spark.network.timeout,600s)
(spark.master,spark://147.75.202.66:7077)
(spark.app.name,JMH prof: LogisticRegressionWithLBFGS)
(spark.jars,/home/hsuehku1/Experiments_GRSM/jmh-spark/treeAggregate/.target/tmp-benchmarks.jar)
<failure>

org.apache.spark.SparkException: Task not serializable
	at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:298)
	at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:288)
	at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:108)
	at org.apache.spark.SparkContext.clean(SparkContext.scala:2094)
	at org.apache.spark.rdd.RDD$$anonfun$map$1.apply(RDD.scala:370)
	at org.apache.spark.rdd.RDD$$anonfun$map$1.apply(RDD.scala:369)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)
	at org.apache.spark.rdd.RDD.map(RDD.scala:369)
	at grsm.Benchmarks.Binary_LRi_acc(driver.scala:116)
	at grsm.generated.Benchmarks_Binary_LRi_acc_jmhTest.Binary_LRi_acc_ss_jmhStub(Benchmarks_Binary_LRi_acc_jmhTest.java:425)
	at grsm.generated.Benchmarks_Binary_LRi_acc_jmhTest.Binary_LRi_acc_SingleShotTime(Benchmarks_Binary_LRi_acc_jmhTest.java:379)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.openjdk.jmh.runner.BenchmarkHandler$BenchmarkTask.call(BenchmarkHandler.java:453)
	at org.openjdk.jmh.runner.BenchmarkHandler$BenchmarkTask.call(BenchmarkHandler.java:437)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.NotSerializableException: grsm.generated.Benchmarks_My_State_jmhType
Serialization stack:
	- object not serializable (class: grsm.generated.Benchmarks_My_State_jmhType, value: grsm.generated.Benchmarks_My_State_jmhType@7898951d)
	- field (class: grsm.Benchmarks$$anonfun$3, name: s$2, type: class grsm.Benchmarks$My_State)
	- object (class grsm.Benchmarks$$anonfun$3, <function1>)
	at org.apache.spark.serializer.SerializationDebugger$.improveException(SerializationDebugger.scala:40)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)
	at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:295)
	... 24 more




# JMH version: 1.19
# VM version: JDK 1.8.0-release, VM 25.71-b00
# VM invoker: /CMC/kmiecseb/jdk8u-server-release-1708/jre/bin/java
# VM options: -Xmx24g
# Warmup: 1 iterations, single-shot each
# Measurement: 5 iterations, single-shot each
# Timeout: 10 min per iteration
# Threads: 1 thread
# Benchmark mode: Single shot invocation time
# Benchmark: grsm.Benchmarks.Multinomial_LR

# Run progress: 46.67% complete, ETA 00:15:42
# Fork: 1 of 1
# Warmup Iteration   1: 

(spark.network.timeout,600s)
(spark.master,spark://147.75.202.66:7077)
(spark.app.name,JMH prof: LogisticRegressionWithLBFGS)
(spark.jars,/home/hsuehku1/Experiments_GRSM/jmh-spark/treeAggregate/.target/tmp-benchmarks.jar)
(*interrupt*) <failure>

java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:998)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
	at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:202)
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:218)
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:153)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:619)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1981)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)
	at org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)
	at org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1127)
	at org.apache.spark.mllib.optimization.LBFGS$CostFun.calculate(LBFGS.scala:244)
	at org.apache.spark.mllib.optimization.LBFGS$CostFun.calculate(LBFGS.scala:230)
	at breeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:23)
	at breeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:41)
	at breeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:30)
	at breeze.optimize.StrongWolfeLineSearch.breeze$optimize$StrongWolfeLineSearch$$phi$1(StrongWolfe.scala:69)
	at breeze.optimize.StrongWolfeLineSearch$$anonfun$minimize$1.apply$mcVI$sp(StrongWolfe.scala:142)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at breeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:141)
	at breeze.optimize.LBFGS.determineStepSize(LBFGS.scala:78)
	at breeze.optimize.LBFGS.determineStepSize(LBFGS.scala:40)
	at breeze.optimize.FirstOrderMinimizer$$anonfun$infiniteIterations$1.apply(FirstOrderMinimizer.scala:64)
	at breeze.optimize.FirstOrderMinimizer$$anonfun$infiniteIterations$1.apply(FirstOrderMinimizer.scala:62)
	at scala.collection.Iterator$$anon$7.next(Iterator.scala:129)
	at breeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:71)
	at org.apache.spark.mllib.optimization.LBFGS$.runLBFGS(LBFGS.scala:212)
	at org.apache.spark.mllib.optimization.LBFGS.optimize(LBFGS.scala:142)
	at org.apache.spark.mllib.regression.GeneralizedLinearAlgorithm.run(GeneralizedLinearAlgorithm.scala:313)
	at org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS.run(LogisticRegression.scala:464)
	at org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS.run(LogisticRegression.scala:407)
	at grsm.Benchmarks.Multinomial_LR(driver.scala:71)
	at grsm.generated.Benchmarks_Multinomial_LR_jmhTest.Multinomial_LR_ss_jmhStub(Benchmarks_Multinomial_LR_jmhTest.java:425)
	at grsm.generated.Benchmarks_Multinomial_LR_jmhTest.Multinomial_LR_SingleShotTime(Benchmarks_Multinomial_LR_jmhTest.java:379)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.openjdk.jmh.runner.BenchmarkHandler$BenchmarkTask.call(BenchmarkHandler.java:453)
	at org.openjdk.jmh.runner.BenchmarkHandler$BenchmarkTask.call(BenchmarkHandler.java:437)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)




# JMH version: 1.19
# VM version: JDK 1.8.0-release, VM 25.71-b00
# VM invoker: /CMC/kmiecseb/jdk8u-server-release-1708/jre/bin/java
# VM options: -Xmx24g
# Warmup: 1 iterations, single-shot each
# Measurement: 1 iterations, single-shot each
# Timeout: 10 min per iteration
# Threads: 1 thread
# Benchmark mode: Single shot invocation time
# Benchmark: grsm.Benchmarks.Multinomial_LR_acc

# Run progress: 86.67% complete, ETA 00:03:39
# Fork: 1 of 1
# Warmup Iteration   1: 

(spark.network.timeout,600s)
(spark.master,spark://147.75.202.66:7077)
(spark.app.name,JMH prof: LogisticRegressionWithLBFGS)
(spark.jars,/home/hsuehku1/Experiments_GRSM/jmh-spark/treeAggregate/.target/tmp-benchmarks.jar)
(*interrupt*) <failure>

java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:998)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
	at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:202)
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:218)
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:153)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:619)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1981)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)
	at org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)
	at org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1127)
	at org.apache.spark.mllib.optimization.LBFGS$CostFun.calculate(LBFGS.scala:244)
	at org.apache.spark.mllib.optimization.LBFGS$CostFun.calculate(LBFGS.scala:230)
	at breeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:23)
	at breeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:41)
	at breeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:30)
	at breeze.optimize.StrongWolfeLineSearch.breeze$optimize$StrongWolfeLineSearch$$phi$1(StrongWolfe.scala:69)
	at breeze.optimize.StrongWolfeLineSearch$$anonfun$minimize$1.apply$mcVI$sp(StrongWolfe.scala:142)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at breeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:141)
	at breeze.optimize.LBFGS.determineStepSize(LBFGS.scala:78)
	at breeze.optimize.LBFGS.determineStepSize(LBFGS.scala:40)
	at breeze.optimize.FirstOrderMinimizer$$anonfun$infiniteIterations$1.apply(FirstOrderMinimizer.scala:64)
	at breeze.optimize.FirstOrderMinimizer$$anonfun$infiniteIterations$1.apply(FirstOrderMinimizer.scala:62)
	at scala.collection.Iterator$$anon$7.next(Iterator.scala:129)
	at breeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:71)
	at org.apache.spark.mllib.optimization.LBFGS$.runLBFGS(LBFGS.scala:212)
	at org.apache.spark.mllib.optimization.LBFGS.optimize(LBFGS.scala:142)
	at org.apache.spark.mllib.regression.GeneralizedLinearAlgorithm.run(GeneralizedLinearAlgorithm.scala:313)
	at org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS.run(LogisticRegression.scala:464)
	at org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS.run(LogisticRegression.scala:407)
	at grsm.Benchmarks.Multinomial_LR_acc(driver.scala:95)
	at grsm.generated.Benchmarks_Multinomial_LR_acc_jmhTest.Multinomial_LR_acc_ss_jmhStub(Benchmarks_Multinomial_LR_acc_jmhTest.java:425)
	at grsm.generated.Benchmarks_Multinomial_LR_acc_jmhTest.Multinomial_LR_acc_SingleShotTime(Benchmarks_Multinomial_LR_acc_jmhTest.java:379)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.openjdk.jmh.runner.BenchmarkHandler$BenchmarkTask.call(BenchmarkHandler.java:453)
	at org.openjdk.jmh.runner.BenchmarkHandler$BenchmarkTask.call(BenchmarkHandler.java:437)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)




# Run complete. Total time: 00:33:47

Benchmark             Mode  Cnt    Score   Error  Units
Benchmarks.Binary_LR    ss    5  105.608 ? 2.522   s/op
Wed Dec  6 22:56:39 UTC 2017
[95m===============================================
Finished Spark LR example.
================================================[97m
Wed Dec  6 22:56:39 UTC 2017
Wed Dec  6 22:56:39 UTC 2017
[95m===============================================
Done experiment.
================================================[97m
